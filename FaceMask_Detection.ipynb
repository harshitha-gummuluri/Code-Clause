{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNOIheIQ0IN0g/S1lfFpYDv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshitha-gummuluri/Code-Clause/blob/main/FaceMask_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "from torchvision.io import read_image\n",
        "from torchvision.transforms import Resize\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Optimizer\n",
        "from torch.optim import Adam\n",
        "from torch import Tensor\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "W-BF99sb5G0w"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Class, used by DataLoader\n",
        "class MaskImgDataset(Dataset):\n",
        "    def __init__(self, data_frame):\n",
        "        self.data_path = \"/kaggle/input/face-mask-detection-dataset/images/\"\n",
        "        self.data_frame = data_frame\n",
        "        self.transformations = Resize((100, 100))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_frame[\"File\"])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img = read_image(self.data_path + self.data_frame[\"File\"][index])\n",
        "        label = self.data_frame[\"Label\"][index]\n",
        "\n",
        "        img = self.transformations(img).float()\n",
        "\n",
        "        return img, label"
      ],
      "metadata": {
        "id": "Si_UHLHp5Rpm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the structure and the steps of the model\n",
        "class MaskDetector(nn.Module):\n",
        "    def __init__(self, loss_function):\n",
        "        super(MaskDetector, self).__init__()\n",
        "\n",
        "        self.loss_function = loss_function\n",
        "\n",
        "        self.conv2d_1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=(3,3), padding=(1,1)),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=(2,2))\n",
        "        )\n",
        "\n",
        "        self.conv2d_2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size=(3,3), padding=(1,1)),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=(2,2))\n",
        "        )\n",
        "\n",
        "        self.conv2d_3 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=(3,3), padding=(1,1), stride=(3,3)),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=(2,2))\n",
        "        )\n",
        "\n",
        "        self.linearLayers = nn.Sequential(\n",
        "            nn.Linear(in_features=2048, out_features=1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=1024, out_features=2)\n",
        "        )\n",
        "\n",
        "        for sequential in [self.conv2d_1, self.conv2d_2, self.conv2d_3, self.linearLayers]:\n",
        "            for layer in sequential.children():\n",
        "                if isinstance(layer, (nn.Linear, nn.Conv2d)):\n",
        "                    nn.init.xavier_uniform_(layer.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv2d_1(x)\n",
        "        out = self.conv2d_2(out)\n",
        "        out = self.conv2d_3(out)\n",
        "        out = out.view(-1, 2048)\n",
        "        out = self.linearLayers(out)\n",
        "\n",
        "        return out\n",
        "    def add_optimizer(self, optimizer):\n",
        "        self.optimizer = optimizer\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "OGOfTaQe5yzU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_losses(loss_db):\n",
        "    plt.plot(loss_db)\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")"
      ],
      "metadata": {
        "id": "Km_TwA-w8vRK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One epoch of training\n",
        "def model_train_loop(model, train_DL):\n",
        "    total_loss = 0\n",
        "    total_correct = 0\n",
        "\n",
        "    for inputs, labels in train_DL:  # iterate over batches\n",
        "        # move inputs to GPU if used\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # forward pass\n",
        "        pred = model(inputs)\n",
        "        labels = labels.flatten()\n",
        "        loss = model.loss_function(pred, labels)\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_correct += (pred.argmax(dim = 1) == labels).sum()  # count correct predictions\n",
        "\n",
        "        # backward pass and update parameters\n",
        "        model.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        model.optimizer.step()\n",
        "\n",
        "    return total_loss, total_correct\n",
        "\n",
        "# Train model for num_epochs\n",
        "def model_train(model, train_DL, num_epochs):\n",
        "    loss_db = []\n",
        "    print(\"Started training\")\n",
        "    start = time.time()\n",
        "\n",
        "    for i in range(num_epochs):\n",
        "        loss, correct = model_train_loop(model, train_DL)\n",
        "        loss_db.append(loss)\n",
        "\n",
        "        print(f\"Epoch {i}: Loss {loss:.4f} Accuracy {correct * 100 / len(train_DL.dataset) :.2f}%\")\n",
        "\n",
        "    print(f\"Training took {time.time() - start:.4f}s\")\n",
        "    plot_losses(loss_db)"
      ],
      "metadata": {
        "id": "GzGqi0Ju80fC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict for validation dataset\n",
        "def validate_model(model, val_DL, limit = float('inf')):\n",
        "    total_correct = 0\n",
        "    total = 0\n",
        "    total_masked = 0\n",
        "    total_masked_correct = 0\n",
        "\n",
        "    for inputs, labels in val_DL:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        pred = model(inputs)\n",
        "        labels = labels.flatten()\n",
        "\n",
        "        # Count total correct predictions\n",
        "        total_correct += (pred.argmax(dim = 1) == labels).sum()\n",
        "        total += len(labels)\n",
        "\n",
        "        # Count correctly predicted masked images (true positives)\n",
        "        total_masked += labels.sum()\n",
        "        total_masked_correct += ((pred.argmax(dim=1) == 1) & (labels == 1)).sum()\n",
        "\n",
        "        # If limit is given, only predict for images upto limit\n",
        "        if total >= limit: break\n",
        "\n",
        "    print(f\"Validation accuracy: {total_correct * 100 / total :.2f}%\")\n",
        "    print(f\"Accuracy of identifying masked images: {total_masked_correct * 100 / total_masked :.2f}%\")"
      ],
      "metadata": {
        "id": "Gy8aM-T989Jl"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use GPU if available\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUNQJ3iU9D6h",
        "outputId": "9d93f3c5-efdb-42ba-c5f1-eb80ac78b4e9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing data for training and validation\n",
        "\n",
        "maskDF = pd.read_csv(\"/content/mask_df.csv\")\n",
        "# Split data into training and validation sets\n",
        "train_maskDF, val_maskDF = train_test_split(maskDF, train_size=0.7, random_state=0, stratify=maskDF[\"Label\"])\n",
        "train_maskDF.reset_index(inplace = True, drop = True)\n",
        "val_maskDF.reset_index(inplace = True, drop = True)\n",
        "\n",
        "train_DS = MaskImgDataset(train_maskDF)\n",
        "val_DS = MaskImgDataset(val_maskDF)\n",
        "\n",
        "train_DL = DataLoader(train_DS, batch_size=32, shuffle=True, num_workers=2)\n",
        "val_DL = DataLoader(val_DS, batch_size=32, num_workers=2)\n"
      ],
      "metadata": {
        "id": "B4lqSOB_OZcL"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuring the loss function\n",
        "# Weights are used because the data is unbalanced\n",
        "\n",
        "num_non_mask_images = maskDF[maskDF[\"Label\"] == 0].shape[0]\n",
        "num_mask_images = maskDF[maskDF[\"Label\"] == 1].shape[0]\n",
        "total_images = num_non_mask_images + num_mask_images\n",
        "\n",
        "normed_weights = [1 - num_non_mask_images/total_images, 1 - num_mask_images/total_images]\n",
        "print(\"Weights for [unmasked, masked]:\", normed_weights)\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss(weight = torch.tensor(normed_weights))\n",
        "\n",
        "# initializing the model\n",
        "model = MaskDetector(loss_function)\n",
        "optimizer = Adam(model.parameters(), lr=0.00001)\n",
        "model.add_optimizer(optimizer)\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CO6E6EqVOqgA",
        "outputId": "07f557ae-3301-4824-99b4-4f35d56e8fb1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights for [unmasked, masked]: [0.015228536906614965, 0.984771463093385]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MaskDetector(\n",
              "  (loss_function): CrossEntropyLoss()\n",
              "  (conv2d_1): Sequential(\n",
              "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv2d_2): Sequential(\n",
              "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv2d_3): Sequential(\n",
              "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(3, 3), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (linearLayers): Sequential(\n",
              "    (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=1024, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use model to predict for images outside the dataset\n",
        "labels = [\"No mask\", \"Masked\"]\n",
        "def predict_image(model, img_path, ax = None):\n",
        "    img = read_image(img_path)\n",
        "    re_img = Resize((100, 100))(img).reshape((1, 3, 100, 100)).float()\n",
        "    re_img = re_img.to(device)\n",
        "    pred = model(re_img)\n",
        "    res = pred.argmax(dim = 1)\n",
        "\n",
        "    ax.imshow(img.permute((1, 2, 0)))\n",
        "    ax.set_title(labels[res], fontdict = {'fontsize' : 40})\n",
        "    ax.axis('off')\n",
        ""
      ],
      "metadata": {
        "id": "KmugDP8zPNzS"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_real_images(model, img_dir):\n",
        "    images = os.listdir(img_dir)\n",
        "    fig, axs = plt.subplots(1, len(images), figsize = (50, 10))\n",
        "    for i, img in enumerate(images):\n",
        "        predict_image(model, os.path.join(img_dir, img), axs[i])\n",
        ""
      ],
      "metadata": {
        "id": "Ry3HqTxcP8IB"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images=pd.read_csv( \"/content/train_labels.csv\")"
      ],
      "metadata": {
        "id": "79kwNRXQSMvP"
      },
      "execution_count": 38,
      "outputs": []
    }
  ]
}